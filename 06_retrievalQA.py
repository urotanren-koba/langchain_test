# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# pycryptodomeã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from glob import glob  # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ç”¨
import streamlit as st  # Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIä½œæˆç”¨
from langchain.chat_models import ChatOpenAI  # ChatGPTãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹
from langchain.llms import OpenAI  # OpenAI APIã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹
from langchain.callbacks import get_openai_callback  # OpenAI APIã®ä½¿ç”¨æ–™é‡‘ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«

# PDFé–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from PyPDF2 import PdfReader  # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from langchain.embeddings.openai import OpenAIEmbeddings  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹
from langchain.text_splitter import RecursiveCharacterTextSplitter  # ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹
from langchain.vectorstores import Qdrant  # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ‰±ã†ãŸã‚ã®ã‚¯ãƒ©ã‚¹
from langchain.chains import RetrievalQA  # è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹

# Qdrantï¼ˆãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰é–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams

# ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿å­˜å ´æ‰€ã¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã®è¨­å®š
QDRANT_PATH = "./local_qdrant"
COLLECTION_NAME = "my_collection_2"


def init_page():
    """
    Streamlitã®ãƒšãƒ¼ã‚¸è¨­å®šã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•°
    ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¢ã‚¤ã‚³ãƒ³ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’è¨­å®šã—ã€ã‚³ã‚¹ãƒˆè¨ˆç®—ç”¨ã®é…åˆ—ã‚’åˆæœŸåŒ–
    """
    st.set_page_config(
        page_title="Ask My PDF(s)",
        page_icon="ğŸ¤—"
    )
    st.sidebar.title("Nav")
    st.session_state.costs = []


def select_model():
    """
    ä½¿ç”¨ã™ã‚‹ChatGPTãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹é–¢æ•°
    å„ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨­å®šã—ã€é©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™
    """
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-3.5-16k", "GPT-4", "GPT-4o-mini"))
    
    # ãƒ¢ãƒ‡ãƒ«åã¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è¨­å®š
    if model == "GPT-3.5":
        st.session_state.model_name = "gpt-3.5-turbo"
        st.session_state.max_token = 4096 - 300  # ä½™è£•ã‚’æŒãŸã›ã‚‹ãŸã‚300ãƒˆãƒ¼ã‚¯ãƒ³æ¸›ã‚‰ã™
    elif model == "GPT-3.5-16k":
        st.session_state.model_name = "gpt-3.5-turbo-16k"
        st.session_state.max_token = 16384 - 300
    elif model == "GPT-4":
        st.session_state.model_name = "gpt-4"
        st.session_state.max_token = 8192 - 300
    elif model == "GPT-4o-mini":
        st.session_state.model_name = "gpt-4o-mini"
        st.session_state.max_token = 8192 - 300
    
    return ChatOpenAI(temperature=0, model_name=st.session_state.model_name)


def get_pdf_text():
    """
    PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
    æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—ã¦è¿”ã™
    """
    uploaded_file = st.file_uploader(
        label='Upload your PDF hereğŸ˜‡',
        type='pdf'
    )
    if uploaded_file:
        pdf_reader = PdfReader(uploaded_file)
        text = '\n\n'.join([page.extract_text() for page in pdf_reader.pages])
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            model_name="text-embedding-ada-002",
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’500æ–‡å­—ã”ã¨ã«åˆ†å‰²ï¼ˆæ–‡è„ˆã‚’ä¿æŒã—ã¤ã¤ã€é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ï¼‰
            chunk_size=500,
            chunk_overlap=0,
        )
        return text_splitter.split_text(text)
    else:
        return None


def load_qdrant():
    """
    Qdrantãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ãƒ»èª­ã¿è¾¼ã‚€é–¢æ•°
    ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆã™ã‚‹
    """
    client = QdrantClient(path=QDRANT_PATH)

    # ã™ã¹ã¦ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’å–å¾—
    collections = client.get_collections().collections
    collection_names = [collection.name for collection in collections]

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆ
    if COLLECTION_NAME not in collection_names:
        client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(size=1536, distance=Distance.COSINE),
        )
        print('collection created')

    return Qdrant(
        client=client,
        collection_name=COLLECTION_NAME, 
        embeddings=OpenAIEmbeddings()
    )


def build_vector_store(pdf_text):
    """
    PDFã‹ã‚‰æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹é–¢æ•°
    """
    qdrant = load_qdrant()
    qdrant.add_texts(pdf_text)


def build_qa_model(llm):
    """
    è³ªå•å¿œç­”ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°
    ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢ã—ã€å›ç­”ã‚’ç”Ÿæˆã™ã‚‹
    """
    qdrant = load_qdrant()
    retriever = qdrant.as_retriever(
        search_type="similarity",  # é¡ä¼¼åº¦æ¤œç´¢ã‚’ä½¿ç”¨
        search_kwargs={"k":10}  # ä¸Šä½10ä»¶ã®é–¢é€£æ–‡æ›¸ã‚’å–å¾—
    )
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff", 
        retriever=retriever,
        return_source_documents=True,
        verbose=True
    )


def page_pdf_upload_and_build_vector_db():
    """
    PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‚’ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹
    """
    st.title("PDF Upload")
    container = st.container()
    with container:
        pdf_text = get_pdf_text()
        if pdf_text:
            with st.spinner("Loading PDF ..."):
                build_vector_store(pdf_text)


def ask(qa, query):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    APIã®ä½¿ç”¨ã‚³ã‚¹ãƒˆã‚‚è¨ˆç®—ã™ã‚‹
    """
    with get_openai_callback() as cb:
        answer = qa(query)
    return answer, cb.total_cost


def page_ask_my_pdf():
    """
    è³ªå•å¿œç­”ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã€å›ç­”ã‚’è¡¨ç¤ºã™ã‚‹
    """
    st.title("Ask My PDF(s)")

    llm = select_model()
    container = st.container()
    response_container = st.container()

    with container:
        query = st.text_input("Query: ", key="input")
        if not query:
            answer = None
        else:
            qa = build_qa_model(llm)
            if qa:
                with st.spinner("ChatGPT is typing ..."):
                    answer, cost = ask(qa, query)
                st.session_state.costs.append(cost)
            else:
                answer = None

        if answer:
            with response_container:
                st.markdown("## Answer")
                st.write(answer)


def main():
    """
    ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œé–¢æ•°
    ãƒšãƒ¼ã‚¸ã®åˆæœŸåŒ–ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚³ã‚¹ãƒˆè¡¨ç¤ºã‚’è¡Œã†
    """
    init_page()

    selection = st.sidebar.radio("Go to", ["PDF Upload", "Ask My PDF(s)"])
    if selection == "PDF Upload":
        page_pdf_upload_and_build_vector_db()
    elif selection == "Ask My PDF(s)":
        page_ask_my_pdf()

    # APIã®ä½¿ç”¨ã‚³ã‚¹ãƒˆã‚’è¡¨ç¤º
    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")


if __name__ == '__main__':
    main()