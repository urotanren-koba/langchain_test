import streamlit as st
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.callbacks import get_openai_callback

from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain.document_loaders import YoutubeLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
import yt_dlp
from langchain.schema import Document
import requests

def init_page():
    st.set_page_config(
        page_title="Youtube Summarizer",
        page_icon="ğŸ¤—"
    )
    st.header("Youtube Summarizer ğŸ¤—")
    st.sidebar.title("Options")
    
    # åˆæœŸåŒ–
    if "costs" not in st.session_state:
        st.session_state.costs = []
    if "model_name" not in st.session_state:
        st.session_state.model_name = "gpt-3.5-turbo-16k"
    if "max_token" not in st.session_state:
        st.session_state.max_token = 16384 - 300  # gpt-3.5-turboã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤


def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-4"))
    
    # ãƒ¢ãƒ‡ãƒ«åã®è¨­å®š
    if model == "GPT-3.5":
        st.session_state.model_name = "gpt-3.5-turbo-16k"
        st.session_state.max_token = 16384 - 300
    else:
        st.session_state.model_name = "gpt-4"
        st.session_state.max_token = 8192 - 300
    
    return ChatOpenAI(temperature=0, model_name=st.session_state.model_name)


def get_url_input():
    url = st.text_input("Youtube URL: ", key="input")
    return url


def get_document(url):
    if not url:
        return None
        
    with st.spinner("Fetching Content ..."):
        try:
            ydl_opts = {
                'writesubtitles': True,
                'writeautomaticsub': True,
                'subtitleslangs': ['ja', 'en'],
                'skip_download': True,
            }
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                
                # ã¾ãšæ‰‹å‹•ã§è¿½åŠ ã•ã‚ŒãŸå­—å¹•ã‚’æ¢ã™
                if 'subtitles' in info and info['subtitles']:
                    for lang in ['ja', 'en']:
                        if lang in info['subtitles']:
                            caption_url = info['subtitles'][lang][0]['url']
                            response = requests.get(caption_url)
                            subtitle_content = response.text
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
                            text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
                                chunk_size=st.session_state.max_token,
                                chunk_overlap=0,
                            )
                            texts = text_splitter.split_text(subtitle_content)
                            
                            return [Document(
                                page_content=text,
                                metadata={"source": url, "title": info.get('title', 'Unknown')}
                            ) for text in texts]

                # æ‰‹å‹•å­—å¹•ãŒãªã„å ´åˆã¯è‡ªå‹•å­—å¹•ã‚’æ¢ã™
                if 'automatic_captions' in info and info['automatic_captions']:
                    for lang in ['ja', 'en']:
                        if lang in info['automatic_captions']:
                            caption_url = info['automatic_captions'][lang][0]['url']
                            response = requests.get(caption_url)
                            subtitle_content = response.text
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
                            text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
                                chunk_size=st.session_state.max_token,
                                chunk_overlap=0,
                            )
                            texts = text_splitter.split_text(subtitle_content)
                            
                            return [Document(
                                page_content=text,
                                metadata={"source": url, "title": info.get('title', 'Unknown')}
                            ) for text in texts]

                raise Exception('No captions or automatic subtitles available')

        except Exception as e:
            st.error(f"Failed to fetch video content: {str(e)}")
            return None


def summarize(llm, docs):
    prompt_template = """ä»¥ä¸‹ã¯YouTubeå‹•ç”»ã®å­—å¹•ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ä¸€éƒ¨ã§ã™ã€‚
ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{text}

æ—¥æœ¬èªã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®ãƒã‚¤ãƒ³ãƒˆã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. ä¸»ãªãƒˆãƒ”ãƒƒã‚¯ã‚„è©±é¡Œ
2. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚„ç™ºè¨€
3. å…·ä½“çš„ãªä¾‹ç¤ºã‚„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼ˆã‚ã‚Œã°ï¼‰
"""

    PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])

    with get_openai_callback() as cb:
        chain = load_summarize_chain(
            llm,
            chain_type="map_reduce",
            verbose=True,
            map_prompt=PROMPT,
            combine_prompt=PROMPT
        )
        response = chain(
            {
                "input_documents": docs,
                "token_max": st.session_state.max_token
            },
            return_only_outputs=True
        )
        
    return response['output_text'], cb.total_cost


def main():
    init_page()
    llm = select_model()

    container = st.container()
    response_container = st.container()

    with container:
        url = get_url_input()
        if url:
            document = get_document(url)
            if document:
                with st.spinner("ChatGPT is typing ..."):
                    output_text, cost = summarize(llm, document)
                st.session_state.costs.append(cost)
            else:
                output_text = None
        else:
            output_text = None

    if output_text:
        with response_container:
            st.markdown("## Summary")
            st.write(output_text)
            st.markdown("---")
            st.markdown("## Original Text")
            st.write(document)

    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")


if __name__ == '__main__':
    main()